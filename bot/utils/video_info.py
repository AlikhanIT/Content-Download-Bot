import shutil
import ffmpeg
import yt_dlp
import requests
from PIL import Image
import io
from urllib.parse import urlparse, parse_qs
from aiogram.client.session import aiohttp

# üìπ –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏ —Ä–∞–∑–º–µ—Ä—ã –≤–∏–¥–µ–æ
async def get_video_resolutions_and_sizes(url):
    try:
        proxy = await get_proxy()

        ydl_opts = {
            'proxy': proxy['url'] if proxy else None,
            'skip_download': True
        }
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info_dict = ydl.extract_info(url, download=False)
            formats = info_dict.get("formats", [])
            resolution_sizes = {}
            for fmt in formats:
                width = fmt.get("width")
                height = fmt.get("height")
                filesize = fmt.get("filesize")
                if width and height and filesize:
                    resolution = f"{width}x{height}"
                    filesize_mb = float(filesize) / (1024 * 1024)
                    resolution_sizes[resolution] = max(resolution_sizes.get(resolution, 0), filesize_mb)
            return resolution_sizes
    except Exception as e:
        log_action(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –≤–∏–¥–µ–æ: {e}")
        return {}

# üñºÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–µ–≤—å—é
async def get_thumbnail_bytes(url):
    try:
        response = requests.get(url, stream=True)
        if response.status_code == 200:
            img = Image.open(io.BytesIO(response.content))
            img = img.convert("RGB")
            img.thumbnail((320, 320))
            byte_io = io.BytesIO()
            img.save(byte_io, format="JPEG", optimize=True, quality=85)
            byte_io.seek(0)
            return byte_io
        return None
    except Exception as e:
        log_action(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–≤—å—é: {e}")
        return None

# üìÑ –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ (ID, –Ω–∞–∑–≤–∞–Ω–∏–µ, –ø—Ä–µ–≤—å—é)
def extract_video_id(url):
    parsed = urlparse(url)
    if 'youtube.com' in parsed.netloc:
        if parsed.path.startswith('/shorts/'):
            return parsed.path.split('/shorts/')[1].split('/')[0]
        query = parse_qs(parsed.query)
        return query.get('v', [None])[0]
    elif 'youtu.be' in parsed.netloc:
        return parsed.path.strip('/')
    return None

async def get_video_info(url):
    log_action('‚ö° –ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ oEmbed')

    try:
        video_id = extract_video_id(url)
        if not video_id:
            log_action('‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –≤–∏–¥–µ–æ')
            return None, None, None

        oembed_url = f"https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={video_id}&format=json"

        async with aiohttp.ClientSession() as session:
            async with session.get(oembed_url) as resp:
                if resp.status != 200:
                    raise Exception(f"–û—à–∏–±–∫–∞ oEmbed: {resp.status}")
                data = await resp.json()

        title = data.get("title", "–í–∏–¥–µ–æ")
        thumbnail_url = data.get("thumbnail_url")

        return video_id, title, thumbnail_url

    except Exception as e:
        log_action(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ: {e}")
        return None, None, None

def check_ffmpeg_installed():
    if not shutil.which("ffmpeg"):
        raise EnvironmentError("FFmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –∏ –¥–æ–±–∞–≤—å—Ç–µ –≤ PATH.")


async def get_video_resolution(video_path):
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ffmpeg.probe –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ
        probe = ffmpeg.probe(video_path)
        video_stream = next((stream for stream in probe["streams"] if stream["codec_type"] == "video"), None)
        if video_stream:
            width = int(video_stream["width"])
            height = int(video_stream["height"])
            return width, height
        return None, None  # –ï—Å–ª–∏ –≤–∏–¥–µ–æ—Å—Ç—Ä–∏–º –Ω–µ –Ω–∞–π–¥–µ–Ω
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤–∏–¥–µ–æ: {e} {video_path}")
        return None, None  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏

async def get_proxy():
    proxy = {'ip': '127.0.0.1', 'port': '9050', 'user': '', 'password': ''}  # Tor –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    proxy_url = f"socks5://{proxy['ip']}:{proxy['port']}"
    log_action(f"üõ° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–∫—Å–∏: {proxy_url}")
    return {
        'url': proxy_url,
        'key': f"{proxy['ip']}:{proxy['port']}"
    }
import asyncio
import time
import json
from asyncio import Lock
from bot.utils.log import log_action

# Cache for full yt-dlp dump-json result
_video_info_cache = {}
_cache_lock = Lock()
_cache_events = {}
_CACHE_TTL_SECONDS = 2 * 60 * 60  # 2 hours


async def get_video_info_with_cache(video_url, max_retries=10, delay=5):
    key = (video_url,)
    log_action(f"üì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞: {video_url}")

    wait_for_other = False

    async with _cache_lock:
        entry = _video_info_cache.get(key)
        if entry:
            info, expire_time = entry
            if time.time() < expire_time:
                log_action(f"üì¶ –í–∑—è—Ç–æ –∏–∑ –∫—ç—à–∞ yt-dlp JSON: {video_url}")
                return info
            else:
                _video_info_cache.pop(key, None)

        if key in _cache_events:
            event = _cache_events[key]
            wait_for_other = True
        else:
            event = asyncio.Event()
            _cache_events[key] = event

    if wait_for_other:
        log_action(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∫—ç—à–∞ –æ—Ç –¥—Ä—É–≥–æ–≥–æ –ø–æ—Ç–æ–∫–∞: {video_url}")
        await event.wait()
        async with _cache_lock:
            entry = _video_info_cache.get(key)
            if entry:
                return entry[0]
            else:
                raise Exception("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞ –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è")

    try:
        for attempt in range(1, max_retries + 1):
            try:
                from bot.utils.downloader import YtDlpDownloader
                proxy = await YtDlpDownloader()._get_proxy()
                user_agent = YtDlpDownloader().user_agent.random

                cmd = [
                    "yt-dlp",
                    "--skip-download",
                    "--no-playlist",
                    "--no-warnings",
                    f"--proxy={proxy['url']}",
                    f"--user-agent={user_agent}",
                    "--dump-json",
                    video_url
                ]

                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                stdout, stderr = await process.communicate()

                if process.returncode != 0:
                    raise Exception(f"‚ùå yt-dlp error:\n{stderr.decode()}")

                raw_output = stdout.decode().strip()
                if not raw_output:
                    raise Exception("‚ö†Ô∏è yt-dlp –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã—Ö.")

                info = json.loads(raw_output)

                async with _cache_lock:
                    _video_info_cache[key] = (info, time.time() + _CACHE_TTL_SECONDS)
                    log_action(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ yt-dlp JSON: {video_url}")
                return info

            except Exception as e:
                err_msg = str(e)
                retriable = (
                    "403" in err_msg or
                    "429" in err_msg or
                    "not a bot" in err_msg.lower()
                )
                if retriable:
                    log_action(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries} ‚Äî –æ—à–∏–±–∫–∞: {err_msg.splitlines()[0]}")
                    if attempt < max_retries:
                        await asyncio.sleep(delay)
                        continue
                raise e
    finally:
        async with _cache_lock:
            if key in _cache_events:
                _cache_events[key].set()
                _cache_events.pop(key, None)


async def extract_url_from_info(info, itags, fallback_itags=None):
    fallback_itags = fallback_itags or []
    formats = info.get("formats", [])
    format_map = {f["format_id"]: f["url"] for f in formats if "url" in f}

    for tag in itags:
        if str(tag) in format_map:
            log_action(f"üîó –ù–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –ø–æ itag={tag}")
            return format_map[str(tag)]

    for fallback in fallback_itags:
        if str(fallback) in format_map:
            log_action(f"üîÅ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback itag={fallback}")
            return format_map[str(fallback)]

    raise Exception(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ–¥—Ö–æ–¥—è—â–∏–µ itag: {itags} (fallback: {fallback_itags})")
