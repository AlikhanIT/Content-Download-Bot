import asyncio
import json
import os
import time
import uuid
import subprocess

import aiofiles
import aiohttp
import heapq
import requests
from functools import cached_property

from aiohttp import ClientError
from aiohttp_socks import ProxyConnector
from fake_useragent import UserAgent
from tqdm import tqdm

from bot.utils.log import log_action
from bot.utils.video_info import get_video_info_with_cache, extract_url_from_info


class YtDlpDownloader:
    _instance = None
    DOWNLOAD_DIR = '/downloads'
    QUALITY_ITAG_MAP = {
        "144": "160", "240": "133", "360": "134", "480": "135",
        "720": "136", "1080": "137", "1440": "264", "2160": "266"
    }
    DEFAULT_VIDEO_ITAG = "243"
    DEFAULT_AUDIO_ITAG = "249"
    MAX_RETRIES = 10

    def __new__(cls, max_threads=8, max_queue_size=20):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialize(max_threads, max_queue_size)
            cls._instance._ensure_download_dir()
        return cls._instance

    def _initialize(self, max_threads, max_queue_size):
        self.max_threads = max_threads
        self.queue = asyncio.Queue(maxsize=max_queue_size)
        self.is_running = False
        self.active_tasks = set()

    def _ensure_download_dir(self):
        os.makedirs(self.DOWNLOAD_DIR, exist_ok=True)
        log_action(f"üìÇ –ü–∞–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {self.DOWNLOAD_DIR}")

    @cached_property
    def user_agent(self):
        return UserAgent()

    async def start_workers(self):
        if not self.is_running:
            self.is_running = True
            for _ in range(self.max_threads):
                task = asyncio.create_task(self._worker())
                self.active_tasks.add(task)
                task.add_done_callback(self.active_tasks.discard)

    async def download(self, url, download_type="video", quality="480"):
        await self.start_workers()
        future = asyncio.get_event_loop().create_future()
        await self.queue.put((url, download_type, quality, future))
        return await future

    async def _worker(self):
        while True:
            url, download_type, quality, future = await self.queue.get()
            try:
                result = await self._process_download(url, download_type, quality)
                future.set_result(result)
            except Exception as e:
                future.set_exception(e)
            finally:
                self.queue.task_done()

    async def _process_download(self, url, download_type, quality):
        file_paths = await self._prepare_file_paths(download_type)
        try:
            proxy_ports = [9050, 9052, 9054, 9056, 9058, 9060, 9062, 9064, 9066, 9068, 9070, 9072, 9074, 9076, 9078]

            info = await get_video_info_with_cache(url)

            if download_type == "audio":
                audio_itags = ["249", "250", "251", "140"]
                direct_audio_url = await extract_url_from_info(info, audio_itags)
                await self._download_direct(direct_audio_url, file_paths['audio'], media_type='audio', proxy_ports=proxy_ports)
                return file_paths['audio']

            video_itag = self.QUALITY_ITAG_MAP.get(str(quality), self.DEFAULT_VIDEO_ITAG)

            # üéØ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –∏–∑ —É–∂–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ info
            video_url_task = asyncio.create_task(extract_url_from_info(info, [video_itag]))
            audio_url_task = asyncio.create_task(extract_url_from_info(info, ["249", "250", "251", "140"]))

            results = await asyncio.gather(video_url_task, audio_url_task, return_exceptions=True)

            if any(isinstance(r, Exception) for r in results):
                video_url_task.cancel()
                audio_url_task.cancel()
                for r in results:
                    if isinstance(r, Exception):
                        raise r

            direct_video_url, direct_audio_url = results

            video_task = asyncio.create_task(
                self._download_direct(direct_video_url, file_paths['video'], media_type='video', proxy_ports=proxy_ports)
            )
            audio_task = asyncio.create_task(
                self._download_direct(direct_audio_url, file_paths['audio'], media_type='audio', proxy_ports=proxy_ports)
            )

            results = await asyncio.gather(video_task, audio_task, return_exceptions=True)

            for result in results:
                if isinstance(result, Exception):
                    video_task.cancel()
                    audio_task.cancel()
                    raise result

            return await self._merge_files(file_paths)

        finally:
            if download_type != 'audio':
                await self._cleanup_temp_files(file_paths)

    async def _prepare_file_paths(self, download_type):
        random_name = uuid.uuid4()
        base = {'output': os.path.join(self.DOWNLOAD_DIR, f"{random_name}.mp4")}
        if download_type == "audio":
            base['audio'] = os.path.join(self.DOWNLOAD_DIR, f"{random_name}.m4a")
        else:
            base.update({
                'video': os.path.join(self.DOWNLOAD_DIR, f"{random_name}_video.mp4"),
                'audio': os.path.join(self.DOWNLOAD_DIR, f"{random_name}_audio.m4a")
            })
        return base

    async def _merge_files(self, file_paths):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é FFmpeg —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        log_action("üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ...")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        video_path = file_paths['video']
        audio_path = file_paths['audio']
        output_path = file_paths['output']
        if not os.path.exists(video_path) or not os.path.exists(audio_path):
            error_msg = f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: video={video_path}, audio={audio_path}"
            log_action(error_msg)
            raise FileNotFoundError(error_msg)

        # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è FFmpeg (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤ MP4)
        merge_command = [
            'ffmpeg',
            '-i', video_path,  # –í—Ö–æ–¥–Ω–æ–π –≤–∏–¥–µ–æ —Ñ–∞–π–ª
            '-i', audio_path,  # –í—Ö–æ–¥–Ω–æ–π –∞—É–¥–∏–æ —Ñ–∞–π–ª
            '-c:v', 'copy',  # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ –ø–æ—Ç–æ–∫–∞ –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
            '-c:a', 'copy',  # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞ –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
            '-map', '0:v:0',  # –í—ã–±–æ—Ä –≤–∏–¥–µ–æ –ø–æ—Ç–æ–∫–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            '-map', '1:a:0',  # –í—ã–±–æ—Ä –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞ –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            '-f', 'mp4',  # –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ MP4
            '-y',  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            '-shortest',  # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∏ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ —Å–∞–º–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            output_path  # –í—ã—Ö–æ–¥–Ω–æ–π MP4 —Ñ–∞–π–ª
        ]

        log_action(f"–í—ã–ø–æ–ª–Ω—è—é –∫–æ–º–∞–Ω–¥—É: {' '.join(merge_command)}")

        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ FFmpeg
        merge_process = await asyncio.create_subprocess_exec(
            *merge_command,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await merge_process.communicate()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if merge_process.returncode == 0:
            log_action(f"‚úÖ –ì–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {output_path}")
            return output_path
        else:
            error_message = stderr.decode().strip() if stderr else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ FFmpeg"
            log_action(f"–û—à–∏–±–∫–∞ FFmpeg (–∫–æ–¥ {merge_process.returncode}): {error_message}")
            raise subprocess.CalledProcessError(merge_process.returncode, merge_command, output=stdout, stderr=stderr)

    async def _cleanup_temp_files(self, file_paths):
        for key in ['video', 'audio']:
            try:
                if os.path.exists(file_paths[key]):
                    os.remove(file_paths[key])
                    log_action(f"üßπ –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_paths[key]}")
            except Exception as e:
                log_action(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}")

    async def _get_direct_url(self, video_url, itags, fallback_itags=None):
        info = await get_video_info_with_cache(video_url)
        return await extract_url_from_info(info, itags, fallback_itags)

    def download_chunk(url, start, end, file, max_speed, pbar):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∫—É—Å–∫–∞ —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        headers = {
            'Range': f'bytes={start}-{end}',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': '*/*',
            'Referer': 'https://www.youtube.com/'
        }
        try:
            with requests.get(url, headers=headers, stream=True, timeout=10) as r:
                r.raise_for_status()
                chunk_size = 32768  # 32 KB
                for chunk in r.iter_content(chunk_size=chunk_size):
                    if chunk:
                        start_time = time.time()
                        with file.get_lock():  # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏
                            file.seek(start)
                            size = file.write(chunk)
                            pbar.update(size)

                        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏
                        expected_time = len(chunk) / max_speed
                        elapsed_time = time.time() - start_time
                        if elapsed_time < expected_time:
                            time.sleep(expected_time - elapsed_time)
        except Exception as e:
            log_action(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫—É—Å–∫–µ {start}-{end}: {e}")

    async def _download_direct(self, url, filename, media_type, proxy_ports=None, num_parts=None):
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
                'Accept': '*/*',
                'Referer': 'https://www.youtube.com/'
            }

            timeout = aiohttp.ClientTimeout(total=600)

            redirect_count = 0
            max_redirects = 10
            current_url = url
            total = 0

            default_port = 9050
            ports = proxy_ports or [default_port]

            connector = ProxyConnector.from_url(f'socks5://127.0.0.1:{ports[0]}')
            async with aiohttp.ClientSession(headers=headers, timeout=timeout, connector=connector) as session:
                while redirect_count < max_redirects:
                    async with session.head(current_url, allow_redirects=False) as r:
                        if r.status in (301, 302, 303, 307, 308):
                            location = r.headers.get('Location')
                            if not location:
                                raise ValueError("–ù–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ Location –ø—Ä–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç–µ")
                            log_action(f"üîÅ –†–µ–¥–∏—Ä–µ–∫—Ç #{redirect_count + 1}: {location}")
                            current_url = location
                            redirect_count += 1
                            continue
                        r.raise_for_status()
                        total = int(r.headers.get('Content-Length', 0))
                        if total == 0:
                            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞")
                        break

                if redirect_count >= max_redirects:
                    raise ValueError(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤ ({max_redirects})")

            total_mb = total / (1024 * 1024)
            log_action(f"‚¨áÔ∏è –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ {media_type.upper()}: {total_mb:.2f} MB ‚Äî {filename}")

            if media_type == 'audio':
                num_parts = num_parts or min(64, max(8, total // (1 * 1024 * 1024)))
            elif total < 100 * 1024 * 1024:
                num_parts = num_parts or min(96, max(16, total // (256 * 1024)))
            else:
                num_parts = num_parts or min(128, max(16, total // (5 * 1024 * 1024)))

            log_action(f"üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —á–∞—Å—Ç–µ–π: {num_parts}")

            part_size = max(total // num_parts, 512 * 1024)

            ranges = []
            tail_boost_threshold = int(total * 0.85)
            i = 0
            while i < total:
                chunk = max(part_size // 2, 256 * 1024) if i >= tail_boost_threshold else part_size
                end = min(i + chunk - 1, total - 1)
                ranges.append((i, end))
                i += chunk

            prioritized_ranges = [(end - start, idx) for idx, (start, end) in enumerate(ranges)]
            heapq.heapify(prioritized_ranges)

            pbar = tqdm(total=total, unit='B', unit_scale=True, unit_divisor=1024, desc=media_type.upper())
            speed_map = {}
            start_time_all = time.time()

            sessions = {}
            for port in ports:
                connector = ProxyConnector.from_url(f'socks5://127.0.0.1:{port}')
                sessions[port] = aiohttp.ClientSession(headers=headers, timeout=timeout, connector=connector)

            completed = set()
            semaphore = asyncio.Semaphore(16)

            async def download_range(index):
                start, end = ranges[index]
                stream_id = f"{start}-{end}"
                part_file = f"{filename}.part{index}"
                port = ports[index % len(ports)]
                session = sessions[port]

                max_attempts = 5
                for attempt in range(1, max_attempts + 1):
                    try:
                        downloaded = 0
                        start_time = time.time()
                        range_headers = headers.copy()
                        range_headers['Range'] = f'bytes={start}-{end}'
                        async with semaphore:
                            async with session.get(current_url, headers=range_headers) as resp:
                                if resp.status in (403, 429, 409):
                                    raise aiohttp.ClientResponseError(resp.request_info, (), status=resp.status,
                                                                      message="Forbidden, Rate Limited or Conflict")
                                resp.raise_for_status()
                                async with aiofiles.open(part_file, 'wb') as f:
                                    async for chunk in resp.content.iter_chunked(1024 * 1024):
                                        await f.write(chunk)
                                        chunk_len = len(chunk)
                                        downloaded += chunk_len
                                        pbar.update(chunk_len)

                        end_time = time.time()
                        duration = end_time - start_time
                        speed = downloaded / duration if duration > 0 else 0
                        speed_map[stream_id] = speed
                        completed.add(index)
                        return

                    except aiohttp.ClientResponseError as e:
                        if attempt < max_attempts:
                            log_action(
                                f"‚ö†Ô∏è {e.status} –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ {stream_id}, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 10 —Å–µ–∫ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts})")
                            await asyncio.sleep(10)
                        else:
                            log_action(f"‚ùå –û—à–∏–±–∫–∞ {e.status} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ {stream_id}: {e}")
                    except Exception as e:
                        if attempt < max_attempts:
                            log_action(
                                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ {stream_id}: {e} (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts})")
                            await asyncio.sleep(5)
                        else:
                            log_action(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ {stream_id}: {e}")

            async def download_all():
                active = set()
                while prioritized_ranges or active:
                    while len(active) < 16 and prioritized_ranges:
                        _, index = heapq.heappop(prioritized_ranges)
                        task = asyncio.create_task(download_range(index))
                        active.add(task)
                    done, active = await asyncio.wait(active, return_when=asyncio.FIRST_COMPLETED)

            await download_all()
            pbar.close()

            async with aiofiles.open(filename, 'wb') as outfile:
                for i in range(len(ranges)):
                    part_file = f"{filename}.part{i}"
                    async with aiofiles.open(part_file, 'rb') as pf:
                        while True:
                            chunk = await pf.read(1024 * 1024)
                            if not chunk:
                                break
                            await outfile.write(chunk)
                    os.remove(part_file)

            for session in sessions.values():
                await session.close()

            end_time_all = time.time()
            total_time = end_time_all - start_time_all
            avg_speed = total / total_time / (1024 * 1024)
            log_action(f"üìä –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫ | –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {avg_speed:.2f} MB/s")

            if speed_map:
                slowest = sorted(speed_map.items(), key=lambda x: x[1])[:5]
                for stream, spd in slowest:
                    log_action(f"üêº –ú–µ–¥–ª–µ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ {stream}: {spd / 1024:.2f} KB/s")

            log_action(f"‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {filename}")

        except Exception as e:
            log_action(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {filename}: {e}")

    async def _get_proxy(self):
        proxy = {'ip': '127.0.0.1', 'port': '9050'}
        proxy_url = f"socks5://{proxy['ip']}:{proxy['port']}"
        log_action(f"üõ° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Å—ã–ª–∫–∏: {proxy_url}")
        return {'url': proxy_url, 'key': f"{proxy['ip']}:{proxy['port']}"}

    def _handle_progress(self, d):
        status = d.get('status')
        if status == 'downloading':
            speed = d.get('speed', 0)
            eta = d.get('eta', 0)
            total = d.get('total_bytes') or d.get('total_bytes_estimate') or 0
            done = d.get('downloaded_bytes', 0)
            percent = (done / total * 100) if total else 0

            log_action(
                f"‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–Ω–∏–µ: {percent:.2f}% | –†–∞–∑–º–µ—Ä: {total / 2**20:.2f} MB | "
                f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {done / 2**20:.2f} MB | –°–∫–æ—Ä–æ—Å—Ç—å: {speed / 2**20:.2f} MB/s | –û—Å—Ç–∞–ª–æ—Å—å: {eta}s"
            )
        elif status == 'finished':
            log_action(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {d.get('filename', '–§–∞–π–ª –Ω–µ —É–∫–∞–∑–∞–Ω')}")
        elif status == 'error':
            log_action(f"‚ùå –û—à–∏–±–∫–∞: {d.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
        else:
            log_action(f"‚ÑπÔ∏è –°—Ç–∞—Ç—É—Å: {d}")
